{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage.transform as image_transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorDataset(Dataset):\n",
    "    def __init__(self,root,size = (128,128)):\n",
    "        self.root         = root\n",
    "        self.class_names  = os.listdir(self.root)\n",
    "        self.size         = size\n",
    "\n",
    "    def __len__(self):\n",
    "        dataset_size = 0\n",
    "        \n",
    "        for cur_class in self.class_names:\n",
    "            dataset_size += len(os.listdir(self.root + cur_class + '/'))\n",
    "            \n",
    "        return dataset_size\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        cur_dataset_size = 0\n",
    "        class_label      = 0\n",
    "        image_index      = index\n",
    "        \n",
    "        for cur_class in self.class_names:\n",
    "            image_index = index - cur_dataset_size\n",
    "            \n",
    "            cur_path       = self.root + cur_class + '/'\n",
    "            files_in_class = os.listdir(cur_path)\n",
    "            \n",
    "            cur_dataset_size += len(files_in_class)\n",
    "            \n",
    "            if(index < cur_dataset_size):\n",
    "                image = np.asarray(Image.open(cur_path + files_in_class[image_index]),dtype=np.double)\n",
    "                \n",
    "                if len(image.shape) == 3:\n",
    "                    image = image[:,:,0]\n",
    "                \n",
    "                image = np.expand_dims(image_transform.resize(image,self.size),axis = 0)\n",
    "                return (image,class_label)\n",
    "            \n",
    "            class_label += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the training dataset and show an example with and without tumors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_set  = 'brain_tumor_dataset/train/'\n",
    "path_val_set    = 'brain_tumor_dataset/val/'\n",
    "\n",
    "dataset_train    = TumorDataset(path_train_set)\n",
    "dataset_validate = TumorDataset(path_val_set)\n",
    "\n",
    "print('Training Dataset Length:    %d' % (len(dataset_train)))\n",
    "print('Validation  Dataset Length: %d' % (len(dataset_validate)))\n",
    "\n",
    "print('Tumor Example')\n",
    "index = 10\n",
    "print(' image:')\n",
    "pyplot.imshow(np.squeeze(dataset_train[index][0]),cmap = 'gray')\n",
    "pyplot.show()\n",
    "print(' label: %d' % dataset_train[index][1])\n",
    "\n",
    "print('Non-Tumor Example')\n",
    "index = 200\n",
    "print(' image:')\n",
    "pyplot.imshow(np.squeeze(dataset_train[index][0]),cmap = 'gray')\n",
    "pyplot.show()\n",
    "print(' label: %d' % dataset_train[index][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TumorClassificationModel(torch.nn.Module):\n",
    "    def __init__(self,kernel_size = 5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.maxpool    = torch.nn.MaxPool2d(2,2)\n",
    "            \n",
    "        self.convlayer1      = torch.nn.Conv2d(in_channels=1,out_channels=6,kernel_size=kernel_size)\n",
    "        self.convlayer2      = torch.nn.Conv2d(in_channels=6,out_channels=15,kernel_size=kernel_size)\n",
    "        \n",
    "        self.fully_connected1 = torch.nn.Linear(15 * 29 * 29, 120)\n",
    "        self.fully_connected2 = torch.nn.Linear(120,60)\n",
    "        self.fully_connected3 = torch.nn.Linear(60,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.maxpool(torch.nn.functional.relu(self.convlayer1(x)))\n",
    "        x = self.maxpool(torch.nn.functional.relu(self.convlayer2(x)))\n",
    "        \n",
    "        x   = torch.nn.functional.relu(self.fully_connected1(x.view(-1,15*29*29)))\n",
    "        x   = torch.nn.functional.relu(self.fully_connected2(x))\n",
    "        out = torch.sigmoid(self.fully_connected3(x))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs     = 4\n",
    "learning_rate  = .00001\n",
    "batch          = 10\n",
    "\n",
    "model = TumorClassificationModel().double()\n",
    "\n",
    "loss_function  = torch.nn.BCELoss()\n",
    "optimizer      = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
    "\n",
    "dataloader_training = DataLoader(dataset_train,batch_size = batch,shuffle=True)\n",
    "dataloader_validate = DataLoader(dataset_validate,batch_size = batch)\n",
    "\n",
    "training_loss   = np.zeros(num_epochs)\n",
    "validation_loss = np.zeros(num_epochs)\n",
    "\n",
    "print('~~~~~~~~~~~~~~~~~')\n",
    "print('Starting Training')\n",
    "print('~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch %d\" % (epoch + 1))\n",
    "    \n",
    "    #Loop through the dataset in batches\n",
    "    for i_batch, sampled_batch in enumerate(dataloader_training):\n",
    "        cur_images = sampled_batch[0]\n",
    "        cur_labels = torch.unsqueeze(sampled_batch[1],1).double()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(cur_images)\n",
    "        loss    = loss_function(outputs,cur_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss[epoch] += loss.item()\n",
    "        \n",
    "    #Loop through the validation set to compute validation loss\n",
    "    for i_batch, sampled_batch in enumerate(dataloader_training):\n",
    "        cur_images = sampled_batch[0]\n",
    "        cur_labels = torch.unsqueeze(sampled_batch[1],1).double()\n",
    "        \n",
    "        outputs = model(cur_images)\n",
    "        \n",
    "        loss = loss_function(outputs,cur_labels)\n",
    "        \n",
    "        validation_loss[epoch] =+ loss.item()\n",
    "    \n",
    "    print(\"  training   loss: %.2f\" % (training_loss[epoch]))\n",
    "    print(\"  validation loss: %.2f\" % (validation_loss[epoch]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Validation and Training Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_validation = 0\n",
    "for i_batch, sampled_batch in enumerate(dataloader_validate):\n",
    "    cur_images = sampled_batch[0]\n",
    "    cur_labels = torch.unsqueeze(sampled_batch[1],1).double()\n",
    "    \n",
    "    classifications = model(cur_images).detach().numpy()\n",
    "    labels          = cur_labels.detach().numpy()\n",
    "    \n",
    "    classifications[classifications > .5]  = 1\n",
    "    classifications[classifications <= .5] = 0\n",
    "    \n",
    "    correct_validation += np.sum(classifications == labels) / len(dataset_validate)\n",
    "    \n",
    "correct_training = 0\n",
    "for i_batch, sampled_batch in enumerate(dataloader_training):\n",
    "    cur_images = sampled_batch[0]\n",
    "    cur_labels = torch.unsqueeze(sampled_batch[1],1).double()\n",
    "    \n",
    "    classifications = model(cur_images).detach().numpy()\n",
    "    labels          = cur_labels.detach().numpy()\n",
    "    \n",
    "    classifications[classifications > .5]  = 1\n",
    "    classifications[classifications <= .5] = 0\n",
    "    \n",
    "    correct_training += np.sum(classifications == labels) / len(dataset_train)\n",
    "    \n",
    "print('Training   Accuracy:    %.2f' % (correct_training * 100))\n",
    "print('Validation Accuracy:    %.2f' % (correct_validation * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
